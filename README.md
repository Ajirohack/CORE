# CORE - Space Project Core Services ğŸš€

A clean, modular microservices architecture for the Space project, providing independent services for workflow processing, multi-agent orchestration, tool execution, and retrieval-augmented generation.

## ğŸ—ï¸ Architecture Overview

The CORE provides a foundation of independent services that communicate with the main Space API:

```
Space API (Main)
â”œâ”€â”€ Engines Service (8001) - Workflow processing
â”œâ”€â”€ LLM Council Service (8002) - Multi-agent orchestration  
â”œâ”€â”€ Packages Service (8003) - Tool registry and execution
â””â”€â”€ RAG Service (8004) - Retrieval-augmented generation
```

## âœ¨ Features

- **ğŸ”„ Independent Services**: Each service runs as a separate FastAPI application
- **ğŸ”§ Modular Design**: Easy to add, remove, or modify services
- **ğŸ“¡ Service Communication**: Standardized HTTP APIs between services
- **ğŸ” Authentication**: JWT-based service authentication
- **ğŸ“Š Monitoring**: Health endpoints and structured logging
- **ğŸ³ Container Ready**: Docker-friendly architecture
- **ğŸ§ª Comprehensive Testing**: Full test suite for all components

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- pip or conda for package management

### Installation

1. **Clone the repository:**

```bash
git clone https://github.com/Ajirohack/CORE.git
cd CORE
```

2. **Install dependencies:**

```bash
# Core dependencies
pip install -r requirements.txt

# Service-specific dependencies
pip install -r engines/requirements.txt
pip install -r packages/requirements.txt
pip install -r llm-council/requirements.txt
pip install -r rag/requirements.txt
```

3. **Start all services:**

```bash
python run_services.py
```

### Alternative: Start Individual Services

```bash
# Terminal 1 - Engines Service
python engines/run_engines.py

# Terminal 2 - LLM Council Service  
python llm-council/run_council.py

# Terminal 3 - Packages Service
python packages/run_packages.py

# Terminal 4 - RAG Service
python rag/run_rag.py
```

## ğŸ” Service Details

### ğŸ”§ Engines Service (Port 8001)

- **Purpose**: Pluggable workflow processing engines
- **Endpoints**: `/health`, `/api/v1/engines/process`
- **Features**: Custom workflow execution, engine registry

### ğŸ¤– LLM Council Service (Port 8002)

- **Purpose**: Multi-agent orchestration and specialist reasoning
- **Endpoints**: `/health`, `/api/v1/council/process`
- **Features**: Agent coordination, specialist prompts, collaborative decision-making

### ğŸ“¦ Packages Service (Port 8003)

- **Purpose**: Tool registry and execution system
- **Endpoints**: `/health`, `/api/v1/packages/process`
- **Features**: Tool management, execution environment, access control

### ğŸ” RAG Service (Port 8004)

- **Purpose**: Retrieval-Augmented Generation with multi-modal storage
- **Endpoints**: `/health`, `/api/v1/rag/process`
- **Features**: Vector storage, knowledge retrieval, multi-modal support

## ğŸ§ª Testing

### Run All Tests

```bash
# Basic import tests
python test_basic_imports.py

# Service initialization tests
python test_service_init.py

# Integration readiness tests
python test_integration_ready.py

# Production readiness check
python production_readiness.py
```

### Health Checks

```bash
# Check all services are running
curl http://localhost:8001/health  # Engines
curl http://localhost:8002/health  # LLM Council
curl http://localhost:8003/health  # Packages
curl http://localhost:8004/health  # RAG
```

## ğŸ“ Project Structure

```
CORE/
â”œâ”€â”€ base_service.py              # Base service class
â”œâ”€â”€ run_services.py              # Service orchestrator
â”œâ”€â”€ services_config.json         # Service configuration
â”œâ”€â”€ requirements.txt             # Core dependencies
â”œâ”€â”€ services/                    # Shared utilities
â”‚   â”œâ”€â”€ auth.py                 # Authentication utilities
â”‚   â”œâ”€â”€ communication.py        # Service communication
â”‚   â””â”€â”€ service_logging.py      # Structured logging
â”œâ”€â”€ engines/                     # Engines service
â”‚   â”œâ”€â”€ engines_service.py
â”‚   â”œâ”€â”€ run_engines.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ llm-council/                 # LLM Council service
â”‚   â”œâ”€â”€ llm_council_service.py
â”‚   â”œâ”€â”€ run_council.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ packages/                    # Packages service
â”‚   â”œâ”€â”€ packages_service.py
â”‚   â”œâ”€â”€ run_packages.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ rag/                        # RAG service
â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”œâ”€â”€ run_rag.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ src/                    # RAG implementation
â””â”€â”€ archived_archivist_components/ # Legacy components
```

## âš™ï¸ Configuration

Edit `services_config.json` to customize:

- Service ports
- Enable/disable services  
- API endpoints
- Service descriptions

Example configuration:

```json
{
  "engines": {
    "port": 8001,
    "enabled": true,
    "description": "Workflow processing engines"
  }
}
```

## ğŸ”§ Development

### Adding a New Service

1. Create service directory: `mkdir new-service`
2. Implement service class extending `BaseService`
3. Create FastAPI runner: `new-service/run_new_service.py`
4. Add to `services_config.json`
5. Update service manager in `run_services.py`

### Service Interface

All services inherit from `BaseService` and provide:

- Health endpoints
- Standardized request/response format
- Authentication integration
- Structured logging

## ğŸ³ Docker Support

```dockerfile
# Example Dockerfile for a service
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "run_services.py"]
```

## ğŸ“Š Monitoring & Logging

- **Health Endpoints**: `/health` on each service
- **Structured Logging**: JSON format with correlation IDs
- **Service Registry**: Automatic service discovery
- **Error Handling**: Comprehensive error tracking

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/new-feature`
3. Make your changes
4. Add tests for new functionality
5. Run the test suite: `python test_basic_imports.py`
6. Commit your changes: `git commit -m "Add new feature"`
7. Push to the branch: `git push origin feature/new-feature`
8. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Documentation**: See `QUICK_START.md` and `CORE_STATUS_REPORT.md`
- **Issues**: Submit issues on GitHub
- **Discussions**: Use GitHub Discussions for questions

## ğŸ‰ Acknowledgments

- Built with FastAPI for high-performance APIs
- Modular architecture inspired by microservices patterns
- Independent service design for scalability and maintainability

---

**Ready to build the future of AI orchestration!** ğŸš€
